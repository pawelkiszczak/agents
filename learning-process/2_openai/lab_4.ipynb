{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, gen_trace_id, function_tool\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from typing import Dict\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given the search term, you search the web for that term and \\\n",
    "    produce concise summary of the results. The summary must have 2-3 paragraphs and less than 300 words. \\\n",
    "    Capture the main points. Write succinctly, not need to have complete sentences or good grammar. This will \\\n",
    "    be consumed by someone synthesizing a report, so it's vital you capture the essence and ignore any fluff. \\\n",
    "    Do not include any additional commentary other than the summary itself.\"\n",
    "    \n",
    "search_agent = Agent(\n",
    "    name='Search Agent',\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[WebSearchTool(search_context_size='low')],\n",
    "    model='gpt-4o-mini',\n",
    "    model_settings=ModelSettings(tool_choice='required')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In 2025, several AI agent frameworks have emerged, each offering unique features for developing intelligent systems:\n",
       "\n",
       "- **LangChain**: A modular framework for building applications with large language models (LLMs), addressing challenges like context retention and multi-step task execution. ([linkedin.com](https://www.linkedin.com/pulse/top-5-frameworks-building-ai-agents-2025-sahil-malhotra-wmisc?utm_source=openai))\n",
       "\n",
       "- **LangGraph**: An extension of LangChain, focusing on stateful, multi-actor systems, ideal for complex workflows and adaptive AI applications. ([linkedin.com](https://www.linkedin.com/pulse/top-5-frameworks-building-ai-agents-2025-sahil-malhotra-wmisc?utm_source=openai))\n",
       "\n",
       "- **CrewAI**: Designed for role-based AI agents, facilitating collaborative problem-solving environments requiring diverse expertise. ([linkedin.com](https://www.linkedin.com/pulse/top-5-frameworks-building-ai-agents-2025-sahil-malhotra-wmisc?utm_source=openai))\n",
       "\n",
       "- **AutoGen**: Developed by Microsoft, it enables advanced multi-agent conversations, tool usage, and memory, integrated with Microsoft's Semantic Kernel and Azure services for secure enterprise deployment. ([medium.com](https://medium.com/%40rajadityasatellite/2025-is-the-year-of-ai-agent-frameworks-cb24e3f9ffc7?utm_source=openai))\n",
       "\n",
       "- **SuperAGI**: An open-source agent framework designed for autonomy, including scheduling, execution monitoring, performance dashboards, and persistent agent memory. ([medium.com](https://medium.com/%40rajadityasatellite/2025-is-the-year-of-ai-agent-frameworks-cb24e3f9ffc7?utm_source=openai))\n",
       "\n",
       "- **AgentCore**: Introduced by AWS, this platform supports enterprise-scale AI agent development and deployment, offering tools for smarter, safer, and more intuitive AI agents. ([techradar.com](https://www.techradar.com/pro/we-want-aws-to-be-the-place-where-everyone-runs-enterprise-ai-agents-the-agentic-era-is-here-for-your-business-so-be-prepared-for-the-new-age?utm_source=openai))\n",
       "\n",
       "- **Agent Lightning**: A flexible framework enabling reinforcement learning-based training of LLMs for any AI agent, decoupling agent execution from training for seamless integration. ([arxiv.org](https://arxiv.org/abs/2508.03680?utm_source=openai))\n",
       "\n",
       "- **AutoAgent**: A fully-automated, zero-code framework for LLM agents, allowing users to create and deploy agents through natural language alone. ([arxiv.org](https://arxiv.org/abs/2502.05957?utm_source=openai))\n",
       "\n",
       "- **AgentLite**: A lightweight library for building and advancing task-oriented LLM agent systems, simplifying the creation and evaluation of new reasoning strategies and agent architectures. ([arxiv.org](https://arxiv.org/abs/2402.15538?utm_source=openai))\n",
       "\n",
       "- **Autono**: A robust autonomous agent framework based on the ReAct paradigm, designed for complex tasks through adaptive decision-making and multi-agent collaboration. ([arxiv.org](https://arxiv.org/abs/2504.04650?utm_source=openai))\n",
       "\n",
       "These frameworks cater to various needs, from enterprise solutions to research applications, reflecting the rapid advancements in AI agent development. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"Latest AT Agent frameworks in 2025\"\n",
    "\n",
    "with trace('WebSearch'):\n",
    "    result = await Runner.run(search_agent, message)\n",
    "\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with usage of Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOW_MANY_SEARCHES = 10\n",
    "\n",
    "INSTRUCTIONS = f\"You are a helpful assistant in research. Given the query, come up with a set of web searches \\\n",
    "    to perform to answer the query as best as you can. Output {HOW_MANY_SEARCHES} terms to query for.\"\n",
    "    \n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query\"\n",
    "    \n",
    "    query: str\n",
    "    \"The search term to /use for the web search\"\n",
    "    \n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"A list of web searches to perform to best answer the query\"\n",
    "    \n",
    "planner_agent = Agent(\n",
    "    name='PlannerAgent',\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model='gpt-4o-mini',\n",
    "    output_type=WebSearchPlan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-13 14:15:55.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1msearches=[WebSearchItem(reason='To find the most current AI agent frameworks released or announced in 2025.', query='latest AI agent frameworks 2025'), WebSearchItem(reason='To get insights on the features and capabilities of upcoming AI agent frameworks.', query='AI agent frameworks features 2025'), WebSearchItem(reason='To explore industry reports or analyses on AI frameworks developing in 2025.', query='2025 AI frameworks industry report'), WebSearchItem(reason='To find user reviews or discussions about new AI frameworks.', query='AI agent framework reviews 2025'), WebSearchItem(reason='To identify major tech companies working on AI agent frameworks in 2025.', query='companies developing AI frameworks 2025'), WebSearchItem(reason='To find academic papers or publications related to AI agent frameworks in 2025.', query='AI agent frameworks research papers 2025'), WebSearchItem(reason='To discover comparisons between different AI agent frameworks in the market.', query='comparison of AI agent frameworks 2025'), WebSearchItem(reason='To see tutorials or guides for implementing new AI frameworks in 2025.', query='implementing AI agent frameworks 2025'), WebSearchItem(reason='To find case studies of organizations using new AI agent frameworks.', query='AI agent framework case studies 2025'), WebSearchItem(reason='To check for online communities or forums discussing 2025 AI agent frameworks.', query='AI agent frameworks community 2025')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search v2\"):\n",
    "    result = await Runner.run(planner_agent, message)\n",
    "\n",
    "logger.info(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "@function_tool\n",
    "def push(\n",
    "    message: str, \n",
    "    device: str = 'iphone', \n",
    "    timeout: int = 5) -> bool:\n",
    "    \"\"\"Send a push notification with given content, i.ex. a mail template.\n",
    "\n",
    "    Args:\n",
    "        message (str): Content of the message being sent\n",
    "        device (str, optional): Name of the device to send notification to. Defaults to 'iphone'.\n",
    "        timeout (int, optional): Timeout value. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if succeeded, False on every other circumstance\n",
    "    \"\"\"\n",
    "    if not all([pushover_user, pushover_token, pushover_url]):\n",
    "        logger.error(\"Pushover configuration is missing.\")\n",
    "        return False\n",
    "\n",
    "    logger.info(\"Sending push notification...\")\n",
    "    \n",
    "    payload = {\n",
    "        \"user\": pushover_user,\n",
    "        \"token\": pushover_token,\n",
    "        \"message\": message,\n",
    "    }\n",
    "    if device:\n",
    "        payload[\"device\"] = device\n",
    "\n",
    "    try:\n",
    "        response = requests.post(pushover_url, data=payload, timeout=timeout)\n",
    "        if response.status_code != 200:\n",
    "            logger.error(f\"Pushover failed: {response.status_code} {response.text}\")\n",
    "            return False\n",
    "        logger.info(\"Push notification sent successfully.\")\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        logger.exception(f\"Error sending push notification: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUSH_INSTRUCTIONS = \"You are able to send nicely formatted push notifications based on a detailed report. \\\n",
    "    You will be provided with a detailed report. You should use your tool to send one email, providing \\\n",
    "    the report converted into clean, wel presented HTML with an appropriate subject line.\"\n",
    "    \n",
    "push_agent = Agent(\n",
    "    name='PushAgent',\n",
    "    instructions=PUSH_INSTRUCTIONS,\n",
    "    tools=[push],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_INSTRUCTION = \"You are a senior research tasked with writing a cohesive report for a research query. \\\n",
    "    You will be provided with an original query and some initial research done by a research assistant. \\\n",
    "    You should first come up with an outline for the report that describes the structure and overall flow \\\n",
    "    of the report. Then, generate the report and return that as your final output. The final output should be \\\n",
    "    in the Markdown format and it should be lengthy and detailed. Aim for 5-10 pages of content, at least 1000 \\\n",
    "    words.\"\n",
    "    \n",
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"A short 3-4 sentence summary of the findings\"\n",
    "    \n",
    "    markdown_report: str\n",
    "    \"The final report\"\n",
    "    \n",
    "    followup_suggestions: list[str]\n",
    "    \"Suggested topics to research further\"\n",
    "    \n",
    "writer_agent = Agent(\n",
    "    name='WriterAgent',\n",
    "    instructions=RESEARCH_INSTRUCTION,\n",
    "    model='gpt-4o-mini',\n",
    "    output_type=ReportData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to plan, execute and perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_searches(query: str):\n",
    "    \"Use the planner_agent to plan which searches to run for a query\"\n",
    "    logger.info(f\"Planning searches...\")\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    logger.info(f\"Will perform {len(result.final_output.searches)} searches\")\n",
    "    return result.final_output\n",
    "\n",
    "async def perform_searches(search_plan: WebSearchPlan):\n",
    "    \"Call search() for each item in the search plan\"\n",
    "    logger.info(f\"Searching...\")\n",
    "    num_completed = 0\n",
    "    tasks = [asyncio.create_task(search(item)) for item in search_plan.searches]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    logger.info(f\"Finished searching\")\n",
    "    return results\n",
    "\n",
    "async def search(item: WebSearchItem):\n",
    "    \"Use the search agent to run a web search for each time item in the search plan\"\n",
    "    input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "    result = await Runner.run(search_agent, input)\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to write and publish the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_report(query: str, search_results: list[str]):\n",
    "    \"Use the writer agent to write a report based on the search results\"\n",
    "    logger.info(f\"Thinking about reports...\")\n",
    "    input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "    result = await Runner.run(writer_agent, input)\n",
    "    logger.info(f\"Finished writing a report\")\n",
    "    return result.final_output\n",
    "\n",
    "async def send_notification(report: ReportData):\n",
    "    \"Use push agent to send a notification with the report\"\n",
    "    logger.info(\"Sending a notification...\")\n",
    "    result = await Runner.run(push_agent, report.markdown_report)\n",
    "    logger.info(\"Report sent\")\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-13 14:16:06.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mStarting research...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:06.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_searches\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mPlanning searches...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:13.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_searches\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mWill perform 10 searches\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:13.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mperform_searches\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mSearching...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:28.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mperform_searches\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mFinished searching\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:28.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwrite_report\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mThinking about reports...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwrite_report\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mFinished writing a report\u001b[0m\n",
      "\u001b[32m2025-08-13 14:16:55.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msend_notification\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSending a notification...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:17:23.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mpush\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mSending push notification...\u001b[0m\n",
      "\u001b[32m2025-08-13 14:17:23.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mpush\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPush notification sent successfully.\u001b[0m\n",
      "\u001b[32m2025-08-13 14:17:25.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msend_notification\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mReport sent\u001b[0m\n",
      "\u001b[32m2025-08-13 14:17:25.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mWorkflow done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Spółki giełdowe w jakie warto intestować w 2025 na GPW\"\n",
    "\n",
    "with trace(\"Research Agent trace\"):\n",
    "    logger.info(f\"Starting research...\")\n",
    "    search_plan = await plan_searches(query)\n",
    "    search_results = await perform_searches(search_plan)\n",
    "    report = await write_report(query, search_results)\n",
    "    report_data = await send_notification(report)\n",
    "    logger.info(\"Workflow done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('report_data_v2.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report_data.markdown_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('report_data_v2.md', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
