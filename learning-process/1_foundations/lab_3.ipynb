{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../../1_foundations/me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../1_foundations/me/summary.txt\", \"r\", encoding='utf-8') as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Ed Donner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are acting as a {name}. You're answering question on {name}'s website, particularly questions\n",
    "related to {name}'s career, background, skills and experience. Your responsibility is to represent\n",
    "{name} for interactions on the website as faithfully as possible. You're given a summary of {name}'s \n",
    "background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as\n",
    "if talking to a potential client or future employer who came across. If you don't know the answer, say so.\n",
    "\n",
    "LinkedIn profile contents: {linkedin}\n",
    "Short {name}'s summary: {summary}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    }] + history + [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "    }]\n",
    "    \n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"\"\"\n",
    "You are an evaluator that decides whether a response to a question is acceptable.\n",
    "You are provided with a conversation betwen a User and an Agent. \n",
    "Your task is to decide whether the Agent's latest response is of acceptable quality.\n",
    "The Agent is playing th role of {name} and is representing {name} on their website.\n",
    "The Agent has been instructed to be professional and engaging, as if taking to a potential client or a future employer.\n",
    "The Agent has been provided with context on {name} in the from of their summary and LinkedIn details.\n",
    "Here's the information:\n",
    "\n",
    "## Summary\n",
    "{summary}\n",
    "\n",
    "## LinkedIn profile\n",
    "{linkedin}\n",
    "\n",
    "With this context, please evaluate the latest response replying whether the response is acceptable and your feedback on this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"\"\"\n",
    "    Here's the conversation between the User and the Agent: \n",
    "    {history}\n",
    "    \n",
    "    Here's the latest message for the User:\n",
    "    {message}\n",
    "    \n",
    "    Here's the latest response from the Agent:\n",
    "    {reply}\n",
    "    \n",
    "    Please evaluate the response replying whether it is acceptable and your feedback on this.\n",
    "    \"\"\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gpt_4o = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation | None:\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": evaluator_system_prompt\n",
    "    }] + history + [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": evaluator_user_prompt(reply, message, history)\n",
    "    }]\n",
    "    \n",
    "    response = gpt_4o.beta.chat.completions.parse(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        response_format=Evaluation\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": system_prompt\n",
    "}] + [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"do you hold a patent?\"\n",
    "}]\n",
    "response = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I hold a patent related to the problem of hiring engineers and the use of AI in that process. The invention focuses on an apparatus for determining role fitness while eliminating unwanted bias. This was a collaborative effort between my team at untapt and GQR, one of the world's fastest-growing recruitment firms. If you'd like to know more about it, feel free to ask!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable. It accurately addresses the user's question about holding a patent, providing details about the patent's focus and collaboration with GQR. The response is professional and engaging, offering to provide more information if desired, which aligns with Ed Donner's representation as a knowledgeable and open professional in the AI and recruitment domains.\")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = f\"\"\"\n",
    "    {system_prompt}\\n\\n\n",
    "    ## Previous answer rejected: You just tried to reply but the quality control rejected your response.\n",
    "    \n",
    "    ## Your attempted answer: \n",
    "    {reply}\n",
    "    \n",
    "    ## Reason for rejection: \n",
    "    {feedback}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": updated_system_prompt\n",
    "    }] + history + [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "    }]\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    system = system_prompt\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system\n",
    "    }] + history + [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "    }]\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    reply = response.choices[0].message.content\n",
    "    \n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    if evaluation.is_acceptable:\n",
    "        print(f\"Evaluation passed\")\n",
    "    else:\n",
    "        print(f\"Evaluation failed - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "        \n",
    "    return reply\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation passed\n",
      "Evaluation passed\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
